{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjppUBfu3xa/kx1MXmIiqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil-4-Pal/Generative-AI-4-ME/blob/main/Generative_Adversarial_Network_using_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network"
      ],
      "metadata": {
        "id": "Se44Xrkn5GQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consist of Two Parts\n",
        "* 1. Generator\n",
        "* 2. Discriminator"
      ],
      "metadata": {
        "id": "H1Jzk6iV5yrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. vanilla Generative Adversarial Network"
      ],
      "metadata": {
        "id": "Zn16Foseanas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "068NSvGQ6TpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self ,img_dims):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Linear(img_dims , 128),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(128,64),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(64,32),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(32,16),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(16,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.disc(x)\n",
        "\n",
        "\n",
        "# class Generator\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self , z_dims ,img_dims ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(z_dims , 256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(256,128),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(128,64),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(64,img_dims),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.gen(x)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 3e-4\n",
        "z_dims = 64\n",
        "img_dims = 28*28*1\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "disc = Discriminator(img_dims).to(device)\n",
        "gen = Generator(z_dims , img_dims).to(device)\n",
        "fixed_noise = torch.randn((batch_size,z_dims)).to(device)\n",
        "transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))]\n",
        ")"
      ],
      "metadata": {
        "id": "UQWfkzv96ume"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading the dataset"
      ],
      "metadata": {
        "id": "ijTPNlqr-Bzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST(root=\"./data\",transform=transforms,download=True)\n",
        "loader = DataLoader(dataset,batch_size=batch_size , shuffle = True)\n",
        "opt_disc = optim.Adam(disc.parameters() , lr = lr)\n",
        "opt_gen = optim.Adam(gen.parameters(),lr =lr)\n",
        "criterion = nn.BCELoss()\n",
        "writer_fake = SummaryWriter(f'runs/GAN_MNIST/fake')\n",
        "writer_real = SummaryWriter(f'runs/GAN_MNIST/real')\n",
        "step = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUXZzbqG-EEN",
        "outputId": "8caf153d-1732-4d56-e942-c311da9da13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.60MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 65.5kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.09MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.83MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline"
      ],
      "metadata": {
        "id": "d1D3c8Ew-_OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx , (real_img , _)  in enumerate(loader):\n",
        "    real_img = real_img.view(-1 ,784).to(device)\n",
        "    batch_size = real_img.shape[0]\n",
        "\n",
        "\n",
        "    # training of the discriminator : here the goal is to maximize the loss log(D(real_img)) + log(1 - D(G(z)))\n",
        "\n",
        "    noise = torch.randn((batch_size,z_dims)).to(device)\n",
        "    fake_img = gen(noise)\n",
        "    disc_real = disc(real_img).view(-1)\n",
        "    lossD_real_img = criterion(disc_real , torch.ones_like(disc_real))\n",
        "    disc_fake  = disc(fake_img).view(-1)\n",
        "    lossD_fake_img = criterion(disc_fake , torch.zeros_like(disc_fake))\n",
        "    lossD = (lossD_real_img + lossD_fake_img) / 2\n",
        "    disc.zero_grad()\n",
        "    lossD.backward(retain_graph = True)\n",
        "    opt_disc.step()\n",
        "\n",
        "\n",
        "    # now to train the generator : here the goal was to minimize the log(1- D(G(z)))  <--> maximizing the log(D(G(z)))\n",
        "\n",
        "    output = disc(fake_img).view(-1)\n",
        "    lossG = criterion(output , torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    lossG.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "\n",
        "    # for tensorboard\n",
        "    if batch_idx == 0 :\n",
        "      print(\n",
        "          f\"epochs[{epoch}/{num_epochs}]\"\n",
        "          f\"loss D :{lossD : .4f} , loss G : {lossG : .4f} \"\n",
        "      )\n",
        "\n",
        "    with torch.no_grad():\n",
        "      fake = gen(fixed_noise).reshape(-1,1,28,28)\n",
        "      data = real_img.reshape(-1,1,28,28)\n",
        "      img_grid_fake = torchvision.utils.make_grid(fake , normalize=True)\n",
        "      img_grid_real = torchvision.utils.make_grid(data , normalize=True)\n",
        "\n",
        "      writer_fake.add_image(\n",
        "          \"MNIST Fake Images\", img_grid_fake , global_step = step\n",
        "      )\n",
        "\n",
        "      writer_real.add_image(\n",
        "          \"MNIST Real Images\" , img_grid_real , global_step = True\n",
        "      )\n",
        "\n",
        "      step +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R6gEAJMV_L1X",
        "outputId": "dee5679a-4ec4-435f-a2ef-f57c119bc13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs[0/100]loss D : 0.6978 , loss G :  0.6259 \n",
            "epochs[1/100]loss D : 0.2237 , loss G :  3.0217 \n",
            "epochs[2/100]loss D : 0.4889 , loss G :  2.0964 \n",
            "epochs[3/100]loss D : 0.4374 , loss G :  1.9016 \n",
            "epochs[4/100]loss D : 0.2808 , loss G :  2.0315 \n",
            "epochs[5/100]loss D : 0.3598 , loss G :  1.2527 \n",
            "epochs[6/100]loss D : 0.1787 , loss G :  3.3664 \n",
            "epochs[7/100]loss D : 0.4384 , loss G :  2.2298 \n",
            "epochs[8/100]loss D : 0.1949 , loss G :  2.2541 \n",
            "epochs[9/100]loss D : 0.1814 , loss G :  1.9875 \n",
            "epochs[10/100]loss D : 0.2593 , loss G :  2.2681 \n",
            "epochs[11/100]loss D : 0.4520 , loss G :  2.0945 \n",
            "epochs[12/100]loss D : 0.3799 , loss G :  1.8802 \n",
            "epochs[13/100]loss D : 0.3664 , loss G :  1.8462 \n",
            "epochs[14/100]loss D : 0.3056 , loss G :  1.6440 \n",
            "epochs[15/100]loss D : 0.4337 , loss G :  1.7643 \n",
            "epochs[16/100]loss D : 0.3630 , loss G :  1.7817 \n",
            "epochs[17/100]loss D : 0.2470 , loss G :  2.4080 \n",
            "epochs[18/100]loss D : 0.3741 , loss G :  1.7184 \n",
            "epochs[19/100]loss D : 0.5323 , loss G :  1.3885 \n",
            "epochs[20/100]loss D : 0.4756 , loss G :  1.7095 \n",
            "epochs[21/100]loss D : 0.3869 , loss G :  1.7044 \n",
            "epochs[22/100]loss D : 0.4116 , loss G :  1.5009 \n",
            "epochs[23/100]loss D : 0.3945 , loss G :  1.6432 \n",
            "epochs[24/100]loss D : 0.4462 , loss G :  1.2851 \n",
            "epochs[25/100]loss D : 0.3085 , loss G :  1.6617 \n",
            "epochs[26/100]loss D : 0.4253 , loss G :  1.4201 \n",
            "epochs[27/100]loss D : 0.4620 , loss G :  1.3982 \n",
            "epochs[28/100]loss D : 0.4152 , loss G :  2.1198 \n",
            "epochs[29/100]loss D : 0.3781 , loss G :  1.5043 \n",
            "epochs[30/100]loss D : 0.3736 , loss G :  1.9770 \n",
            "epochs[31/100]loss D : 0.4551 , loss G :  1.6149 \n",
            "epochs[32/100]loss D : 0.3196 , loss G :  1.7935 \n",
            "epochs[33/100]loss D : 0.3786 , loss G :  1.5082 \n",
            "epochs[34/100]loss D : 0.4351 , loss G :  1.6784 \n",
            "epochs[35/100]loss D : 0.4675 , loss G :  1.6367 \n",
            "epochs[36/100]loss D : 0.3762 , loss G :  1.6425 \n",
            "epochs[37/100]loss D : 0.3723 , loss G :  1.3368 \n",
            "epochs[38/100]loss D : 0.4534 , loss G :  1.2331 \n",
            "epochs[39/100]loss D : 0.3933 , loss G :  1.7403 \n",
            "epochs[40/100]loss D : 0.5084 , loss G :  1.5515 \n",
            "epochs[41/100]loss D : 0.4174 , loss G :  1.2749 \n",
            "epochs[42/100]loss D : 0.4204 , loss G :  1.3951 \n",
            "epochs[43/100]loss D : 0.3737 , loss G :  1.7140 \n",
            "epochs[44/100]loss D : 0.5107 , loss G :  1.5989 \n",
            "epochs[45/100]loss D : 0.4789 , loss G :  1.2112 \n",
            "epochs[46/100]loss D : 0.5125 , loss G :  1.5796 \n",
            "epochs[47/100]loss D : 0.5191 , loss G :  1.0918 \n",
            "epochs[48/100]loss D : 0.4371 , loss G :  1.6434 \n",
            "epochs[49/100]loss D : 0.4713 , loss G :  1.4538 \n",
            "epochs[50/100]loss D : 0.3396 , loss G :  1.4556 \n",
            "epochs[51/100]loss D : 0.5601 , loss G :  1.2634 \n",
            "epochs[52/100]loss D : 0.3668 , loss G :  1.5383 \n",
            "epochs[53/100]loss D : 0.4798 , loss G :  1.6041 \n",
            "epochs[54/100]loss D : 0.4878 , loss G :  1.6125 \n",
            "epochs[55/100]loss D : 0.5113 , loss G :  1.3488 \n",
            "epochs[56/100]loss D : 0.5130 , loss G :  1.4327 \n",
            "epochs[57/100]loss D : 0.4423 , loss G :  1.2908 \n",
            "epochs[58/100]loss D : 0.4529 , loss G :  1.1870 \n",
            "epochs[59/100]loss D : 0.5134 , loss G :  1.0813 \n",
            "epochs[60/100]loss D : 0.4064 , loss G :  1.3808 \n",
            "epochs[61/100]loss D : 0.4630 , loss G :  1.8753 \n",
            "epochs[62/100]loss D : 0.5381 , loss G :  1.4747 \n",
            "epochs[63/100]loss D : 0.3427 , loss G :  1.8424 \n",
            "epochs[64/100]loss D : 0.5947 , loss G :  1.0628 \n",
            "epochs[65/100]loss D : 0.3892 , loss G :  1.8671 \n",
            "epochs[66/100]loss D : 0.3724 , loss G :  1.8428 \n",
            "epochs[67/100]loss D : 0.3809 , loss G :  1.3715 \n",
            "epochs[68/100]loss D : 0.3599 , loss G :  1.3812 \n",
            "epochs[69/100]loss D : 0.5437 , loss G :  1.4816 \n",
            "epochs[70/100]loss D : 0.5364 , loss G :  1.3243 \n",
            "epochs[71/100]loss D : 0.5234 , loss G :  1.6552 \n",
            "epochs[72/100]loss D : 0.5186 , loss G :  1.2603 \n",
            "epochs[73/100]loss D : 0.3828 , loss G :  1.5918 \n",
            "epochs[74/100]loss D : 0.4586 , loss G :  1.3109 \n",
            "epochs[75/100]loss D : 0.4814 , loss G :  1.3854 \n",
            "epochs[76/100]loss D : 0.5385 , loss G :  1.3528 \n",
            "epochs[77/100]loss D : 0.5719 , loss G :  1.5270 \n",
            "epochs[78/100]loss D : 0.4782 , loss G :  1.2856 \n",
            "epochs[79/100]loss D : 0.4583 , loss G :  1.5023 \n",
            "epochs[80/100]loss D : 0.5089 , loss G :  1.4340 \n",
            "epochs[81/100]loss D : 0.4591 , loss G :  1.6783 \n",
            "epochs[82/100]loss D : 0.4850 , loss G :  1.6428 \n",
            "epochs[83/100]loss D : 0.4919 , loss G :  1.7445 \n",
            "epochs[84/100]loss D : 0.4769 , loss G :  1.4654 \n",
            "epochs[85/100]loss D : 0.3912 , loss G :  1.6043 \n",
            "epochs[86/100]loss D : 0.4703 , loss G :  1.6238 \n",
            "epochs[87/100]loss D : 0.3838 , loss G :  1.4487 \n",
            "epochs[88/100]loss D : 0.5300 , loss G :  1.1888 \n",
            "epochs[89/100]loss D : 0.4129 , loss G :  1.9115 \n",
            "epochs[90/100]loss D : 0.5387 , loss G :  1.3598 \n",
            "epochs[91/100]loss D : 0.4643 , loss G :  1.1338 \n",
            "epochs[92/100]loss D : 0.5368 , loss G :  0.9885 \n",
            "epochs[93/100]loss D : 0.5778 , loss G :  1.7564 \n",
            "epochs[94/100]loss D : 0.4474 , loss G :  1.3967 \n",
            "epochs[95/100]loss D : 0.5419 , loss G :  1.6883 \n",
            "epochs[96/100]loss D : 0.4474 , loss G :  1.7306 \n",
            "epochs[97/100]loss D : 0.4711 , loss G :  1.1339 \n",
            "epochs[98/100]loss D : 0.5810 , loss G :  1.4953 \n",
            "epochs[99/100]loss D : 0.3877 , loss G :  1.8190 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Deep Convolutional Generative Adversarial Network"
      ],
      "metadata": {
        "id": "N-ZUFT9cC5wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n"
      ],
      "metadata": {
        "id": "CPkRqO6Ta_1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating Discriminator Class\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self , channels_img , features_d):\n",
        "    super(Discriminator , self).__init__()\n",
        "\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            channels_img , features_d , kernel_size=4 , stride = 2 , padding=1\n",
        "        ),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        self._block(features_d , features_d*2,4,2,1),\n",
        "        self._block(features_d*2 , features_d*4,4,2,1),\n",
        "        self._block(features_d*4 , features_d*8,4,2,1),\n",
        "        nn.Conv2d(features_d*8 ,1,kernel_size=4,stride=2,padding=1 ),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def _block(self , in_channels , out_channels , kernel_size ,  padding , strides):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size ,\n",
        "            strides ,\n",
        "            padding,\n",
        "            bias=False\n",
        "        ),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.disc(x)\n",
        "\n",
        "\n",
        "# Generator Class\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self , z_dims , channels_img ,features_g ):\n",
        "    super(Generator , self).__init__()\n",
        "    self.gen= nn.Sequential(\n",
        "        self._block(z_dims , features_g*16 , 4,2,1),\n",
        "        self._block(features_g*16 , features_g*8 ,4,2,1),\n",
        "        self._block(features_g*8 , features_g*4 , 4,2,1),\n",
        "        self._block(features_g*4 , features_g*2 , 4,2,1),\n",
        "        nn.ConvTranspose2d(\n",
        "            features_g*2 , channels_img , kernel_size=4 ,stride = 2 , padding= 1\n",
        "        ),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def _block(self , in_channels , out_channels , kernel_size , stride , padding):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels , out_channels , kernel_size , stride , padding , bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.gen(x)"
      ],
      "metadata": {
        "id": "Z3CttaLTvAbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the Weights"
      ],
      "metadata": {
        "id": "oAnP_NIJzpPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Initialize_weights(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m , (nn.Conv2d , nn.ConvTranspose2d , nn.BatchNorm2d)):\n",
        "      nn.init.normal_(m.weight.data,0.0,0.02)\n",
        "\n",
        "def test():\n",
        "  N , in_channels , H , W = 8 , 3 , 64 , 64\n",
        "  z_dims = 100\n",
        "  x = torch.randn((N,in_channels , H ,W))\n",
        "  disc = Discriminator(in_channels , 8)\n",
        "  Initialize_weights(disc)\n",
        "  assert disc(x).shape(N,1,1,1)\n",
        "  gen = Generator(z_dims , in_channels , 8)\n",
        "  Initialize_weights(gen)\n",
        "  z = torch.randn((N , z_dims , 1,1))\n",
        "  assert gen(z).shape(N , in_channels ,H,W )\n",
        "  print('Success')\n"
      ],
      "metadata": {
        "id": "NkUagWtSz0m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "-IUPd7vg2oRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "Zw-CeHnVAKIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 2e-4\n",
        "batch_size = 128\n",
        "image_size= 64\n",
        "channel_img = 1\n",
        "z_dims = 100\n",
        "num_epochs = 200\n",
        "features_disc = 64\n",
        "features_gen = 64\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(image_size),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(\n",
        "         [0.5 for _ in range(channel_img)] , [0.5 for _ in range(channel_img)]\n",
        "     )]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3HoQtys7ArsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "9Vd8lqu7CHWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST(root=\",/data\",train =True , download=True , transform=transform)\n",
        "loader = DataLoader(dataset , batch_size= batch_size , shuffle = True)\n",
        "\n",
        "gen = Generator(z_dims , channel_img , features_gen).to(device)\n",
        "disc = Discriminator(channel_img , features_disc).to(device)\n",
        "Initialize_weights(gen)\n",
        "Initialize_weights(disc)\n",
        "\n",
        "opt_gen = optim.Adam(gen.parameters() , lr = learning_rate , betas=(0.5 ,0.999))\n",
        "opt_disc = optim.Adam(disc.parameters() , lr = learning_rate , betas=(0.5 ,0.999))\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(32,z_dims,1,1).to(device)\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "step = 0\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx ,(real_img , _) in enumerate(loader):\n",
        "    real_img = real_img.to(device)\n",
        "    fake_img = gen(fixed_noise)\n",
        "    noise = torch.randn((batch_size , z_dims , 1,1)).to(device)\n",
        "\n",
        "\n",
        "    # training discriminator\n",
        "    disc_real = disc(real_img).reshape(-1)\n",
        "    loss_disc_real = criterion(disc_real , torch.ones_like(disc_real))\n",
        "    disc_fake = disc(fake_img).reshape(-1)\n",
        "    loss_disc_fake = criterion(disc_fake , torch.zeros_like(disc_fake))\n",
        "    loss_disc = (loss_disc_fake+loss_disc_real)/2\n",
        "    disc.zero_grad()\n",
        "    loss_disc.backward(retain_graph=True)\n",
        "    opt_disc.step()\n",
        "\n",
        "    # training generator\n",
        "\n",
        "    output= disc(fake_img).reshape(-1)\n",
        "    loss_gen = criterion(output , torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      fake_img = gen(fixed_noise)\n",
        "\n",
        "      img_grid_real = torchvision.utils.make_grid(\n",
        "          real_img[:32] , normalize=True\n",
        "      )\n",
        "      img_grid_fake = torchvision.utils.make_grid(\n",
        "          fake_img[:32] , normalize=True\n",
        "      )\n",
        "\n",
        "      writer_real.add_image(\"Real\",img_grid_real , global_step=step)\n",
        "      writer_fake.add_image(\"fake\",img_grid_fake, global_step=step)\n",
        "    step +=1"
      ],
      "metadata": {
        "id": "2CdXsFa2CJoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cycle Generative Adversarial Network"
      ],
      "metadata": {
        "id": "2UaVnCVUPqfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disriminator"
      ],
      "metadata": {
        "id": "4mxqG17LtdMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _Block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channels , out_channels , stride):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels , out_channels , 4 , stride , padding = 1 , padding_mode=\"reflect\" ),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "class CGDiscriminator(nn.Module):\n",
        "\n",
        "  def __init__(self , in_channels , features = [64,128,256,512]):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels,\n",
        "            features[0],\n",
        "            kernel_size= 4,\n",
        "            stride=2,\n",
        "            padding =1\n",
        "        ),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    layers = []\n",
        "    in_channels = features[0]\n",
        "    for feature in features[1:]:\n",
        "      layers.append(_Block(in_channels , feature , stride =1 if feature == features[-1] else 2))\n",
        "      in_channels = feature\n",
        "    layers.append(nn.conv2d(in_channels , 1 , kernel_size =4 , stride =1 , padding =1 , padding_mode = 'reflect'  ))\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self ,x):\n",
        "    x = self.initial(x)\n",
        "    return torch.sigmoid(self.model(x))"
      ],
      "metadata": {
        "id": "QtqXl7WtLVWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "dI0CwMSKPggA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self,in_channels , out_channels , down = True , use_act = False , **kwargs ) -> None:\n",
        "    super().__init__()"
      ],
      "metadata": {
        "id": "3VsDfPfQT_xW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}